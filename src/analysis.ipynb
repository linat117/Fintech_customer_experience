{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a1eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f9295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     review  rating        date bank  \\\n",
      "0                                ምንም የማይ ሰራ       1  2025-11-26  BOA   \n",
      "1                                 very good       5  2025-11-25  BOA   \n",
      "2  most of the time is not working properly       1  2025-11-25  BOA   \n",
      "3                              good service       5  2025-11-25  BOA   \n",
      "4                            not use for me       3  2025-11-23  BOA   \n",
      "\n",
      "        source  \n",
      "0  Google Play  \n",
      "1  Google Play  \n",
      "2  Google Play  \n",
      "3  Google Play  \n",
      "4  Google Play  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/clean_reviews.csv\")  \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99272b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1789, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de73573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a211d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\teshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050ed1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28c85866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf276b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d025d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     review           cleaned_text\n",
      "0                                ምንም የማይ ሰራ                       \n",
      "1                                 very good                   good\n",
      "2  most of the time is not working properly  time working properly\n",
      "3                              good service           good service\n",
      "4                            not use for me                    use\n"
     ]
    }
   ],
   "source": [
    "print(df[['review', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6842764",
   "metadata": {},
   "source": [
    "Sentiment analysis started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a6bf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d329146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\teshi\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c325eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4981be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'positive', score\n",
    "    elif score <= -0.05:\n",
    "        return 'negative', score\n",
    "    else:\n",
    "        return 'neutral', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd3d0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sentiment_label', 'sentiment_score']] = df['cleaned_text'].apply(lambda x: pd.Series(get_sentiment(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80bd3de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            cleaned_text sentiment_label  sentiment_score\n",
      "0                                neutral           0.0000\n",
      "1                   good        positive           0.4404\n",
      "2  time working properly         neutral           0.0000\n",
      "3           good service        positive           0.4404\n",
      "4                    use         neutral           0.0000\n"
     ]
    }
   ],
   "source": [
    "print(df[['cleaned_text', 'sentiment_label', 'sentiment_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0054b5",
   "metadata": {},
   "source": [
    "Key word extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1cc006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        keyword  importance\n",
      "44         good  203.815916\n",
      "5           app  203.423781\n",
      "14         best   93.688669\n",
      "60         nice   68.019864\n",
      "10         bank   64.515777\n",
      "11      banking   43.491879\n",
      "89          use   38.771452\n",
      "49         like   35.034529\n",
      "37    excellent   34.994959\n",
      "22       dashen   34.891723\n",
      "7   application   34.726421\n",
      "63          one   33.847635\n",
      "94      working   33.655779\n",
      "62           ok   33.340265\n",
      "46        great   32.906754\n",
      "39         fast   32.159410\n",
      "93         work   31.727015\n",
      "99          wow   30.358187\n",
      "53       mobile   29.474181\n",
      "30         easy   28.339058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=100)  # unigrams & bigrams\n",
    "tfidf_matrix = tfidf.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Get feature names and their importance\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "importance = tfidf_matrix.toarray().sum(axis=0)\n",
    "\n",
    "keywords = pd.DataFrame({'keyword': feature_names, 'importance': importance})\n",
    "keywords = keywords.sort_values(by='importance', ascending=False)\n",
    "print(keywords.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00c85036",
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = {\n",
    "    'Account Access Issues': ['login', 'password', 'account', 'access'],\n",
    "    'Transaction Performance': ['transfer', 'payment', 'slow', 'delay'],\n",
    "    'UI & Experience': ['interface', 'easy', 'app', 'design'],\n",
    "    'Customer Support': ['support', 'help', 'service', 'response']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d16e03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            cleaned_text              themes\n",
      "0                                    [Other]\n",
      "1                   good             [Other]\n",
      "2  time working properly             [Other]\n",
      "3           good service  [Customer Support]\n",
      "4                    use             [Other]\n"
     ]
    }
   ],
   "source": [
    "def assign_theme(text):\n",
    "    matched = []\n",
    "    for theme, keywords_list in themes.items():\n",
    "        for kw in keywords_list:\n",
    "            if kw in text:\n",
    "                matched.append(theme)\n",
    "                break\n",
    "    return matched if matched else ['Other']\n",
    "\n",
    "df['themes'] = df['cleaned_text'].apply(assign_theme)\n",
    "print(df[['cleaned_text', 'themes']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c25ad9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/task2_reviews_analysis.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
